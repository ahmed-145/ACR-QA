# ACR-QA v2.0 - Automated Code Review Platform

**Intelligent, Context-Aware Code Quality Analysis with AI-Powered Explanations**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![PostgreSQL](https://img.shields.io/badge/postgresql-15+-blue.svg)](https://www.postgresql.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ðŸŽ¯ Project Overview

ACR-QA is a language-agnostic code review platform that automatically detects issues, assigns intelligent severity levels, and provides AI-generated explanations grounded in rule definitions.

**Key Features:**
- ðŸ” Multi-tool static analysis (Ruff, Semgrep, Vulture, Radon, jscpd)
- ðŸ§  RAG-enhanced AI explanations (Cerebras Llama 3.1)
- ðŸ“Š Context-aware severity scoring (HIGH/MEDIUM/LOW)
- ðŸš€ GitHub Action integration with PR comments
- ðŸ’¾ Complete provenance tracking
- ðŸ“ˆ Beautiful web dashboard
- ðŸ’° Zero recurring costs (free tier APIs)

---

## ðŸ“Š Demo Results

**Sample Analysis (Run 28):**
```
Total Findings: 56
â”œâ”€ ðŸ”´ HIGH:   1 (SECURITY-001: eval() usage)
â”œâ”€ ðŸŸ¡ MEDIUM: 5 (PATTERN-001, DEAD-001, COMPLEXITY-001)
â””â”€ ðŸŸ¢ LOW:    50 (VAR-001, IMPORT-001, DEAD-001)

AI Explanations: 56/56 generated
Performance: ~90 seconds
Cost: $0.025 per analysis
```

---

## ðŸš€ Quick Start

### Prerequisites
- Python 3.11+
- PostgreSQL 15+
- Node.js 18+ (for jscpd)

### Installation
```bash
# 1. Clone repository
git clone https://github.com/yourusername/acr-qa.git
cd acr-qa

# 2. Install Python dependencies
pip install -r requirements.txt

# 3. Install analysis tools
pip install ruff semgrep vulture radon bandit
npm install -g jscpd

# 4. Set up database
createdb acrqa
psql -d acrqa -f DATABASE/schema.sql

# 5. Configure environment
cp .env.example .env
# Edit .env with your credentials
```

### Run Analysis
```bash
# Analyze a directory
python3 CORE/main.py --target-dir /path/to/code --limit 50

# Start dashboard
python3 FRONTEND/app.py
# Open http://localhost:5000

# Export provenance
python3 scripts/export_provenance.py 28

# Generate report
python3 scripts/generate_report.py 28
```

---

## ðŸ“ Project Structure
```
acr-qa/
â”œâ”€â”€ CORE/
â”‚   â”œâ”€â”€ engines/
â”‚   â”‚   â”œâ”€â”€ severity_scorer.py    # Intelligent severity logic
â”‚   â”‚   â”œâ”€â”€ normalizer.py         # Canonical schema mapper
â”‚   â”‚   â””â”€â”€ explainer.py          # RAG + LLM integration
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ code_extractor.py    # Code snippet extraction
â”‚   â””â”€â”€ main.py                   # Analysis pipeline
â”œâ”€â”€ DATABASE/
â”‚   â”œâ”€â”€ schema.sql                # PostgreSQL schema
â”‚   â””â”€â”€ database.py               # Database interface
â”œâ”€â”€ FRONTEND/
â”‚   â”œâ”€â”€ app.py                    # Flask dashboard
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html            # Modern UI
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ post_pr_comments.py      # GitHub PR integration
â”‚   â”œâ”€â”€ generate_report.py       # Markdown reports
â”‚   â””â”€â”€ export_provenance.py     # Full audit trail
â”œâ”€â”€ TESTS/
â”‚   â””â”€â”€ samples/
â”‚       â””â”€â”€ comprehensive-issues/ # Test files (6 files)
â”œâ”€â”€ TOOLS/
â”‚   â”œâ”€â”€ run_checks.sh            # Tool orchestration
â”‚   â””â”€â”€ semgrep/
â”‚       â””â”€â”€ python-rules.yml     # Custom Semgrep rules
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ acr-qa.yml           # GitHub Action
â””â”€â”€ config/
    â””â”€â”€ rules.yml                 # Rule definitions (RAG knowledge base)
```

---

## ðŸ”§ Architecture

### 1. Analysis Pipeline
```
GitHub PR â†’ Detection Tools â†’ Normalizer â†’ Severity Scorer â†’ LLM Explainer â†’ Database â†’ PR Comments
```

### 2. Severity Scoring
```python
HIGH:   Security vulnerabilities, crashes (eval, SQL injection)
MEDIUM: Design issues, complexity (CC>10, too many params)
LOW:    Style violations, unused code (imports, variables)
```

### 3. RAG Explanation Engine
```
1. Retrieve rule definition from rules.yml
2. Extract code context (3 lines before/after)
3. Construct evidence-grounded prompt
4. Call Cerebras API (Llama 3.1 8B)
5. Validate response cites rule ID
6. Store with provenance
```

---

## ðŸŽ¨ GitHub Action Usage

### Auto-Trigger on PRs
```yaml
# .github/workflows/acr-qa.yml is pre-configured
# Just add CEREBRAS_API_KEY secret to your repo
```

### Manual Trigger

Comment on any PR:
```
acr-qa review
```

The action will analyze changed files and post comments sorted by severity.

---

## ðŸ“Š Dashboard Features

Access at `http://localhost:5000`:

- âœ… Real-time statistics (HIGH/MEDIUM/LOW counts)
- âœ… Severity filtering
- âœ… Category filtering
- âœ… Full-text search
- âœ… Collapsible AI explanations
- âœ… Export provenance data
- âœ… Beautiful modern UI

---

## ðŸ§ª Testing
```bash
# Run comprehensive test suite
python3 CORE/main.py --target-dir TESTS/samples/comprehensive-issues --limit 56

# Expected: 56 findings
#   HIGH: 1-2 (security issues)
#   MEDIUM: 4-6 (design smells)
#   LOW: 50+ (style, unused code)

# Verify severity scorer
python3 CORE/engines/severity_scorer.py
# Expected: 6/6 tests passed
```

---

## ðŸ“ˆ Metrics & Performance

| Metric | Target | Achieved |
|--------|--------|----------|
| Severity Accuracy | 90% | âœ… 100% (6/6 tests) |
| Analysis Time | <120s | âœ… ~90s |
| AI Latency | <1s | âœ… 400-600ms |
| Cost per Analysis | <$0.05 | âœ… $0.025 |
| False Positive Rate | <30% | ðŸ”„ TBD (Phase 2) |

---

## ðŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| Language | Python 3.11 | Core implementation |
| Database | PostgreSQL 15 | Provenance storage |
| AI Model | Cerebras Llama 3.1 8B | Natural language explanations |
| Static Analysis | Ruff, Semgrep, Vulture, Radon | Multi-tool detection |
| Web Framework | Flask + Tailwind CSS | Dashboard UI |
| VCS Integration | GitHub Actions + PyGithub | PR automation |

---

## ðŸ“š Documentation

- [Architecture Details](docs/DOCS/ARCHITECTURE.md)
- [Canonical Schema](docs/DOCS/CANONICAL_SCHEMA.md)
- [API Reference](docs/DOCS/API.md)
- [PRD](docs/prd.pdf)
- [Assignment 1](docs/assigment1_merged.pdf)
- [Assignment 2](docs/assigment2_merged.pdf)

---

## ðŸŽ“ Academic Context

**Student:** Ahmed Mahmoud Abbas (ID: 222101213)  
**Supervisor:** Dr. Samy AbdelNabi  
**Institution:** King Salman International University (KSIU)  
**Timeline:** October 2025 - June 2026  
**Status:** Phase 1 Complete (âœ… Ahead of Schedule)

---

## ðŸš§ Roadmap

### Phase 1 (âœ… COMPLETE - Jan 2, 2026)
- [x] Python adapter with 5 detection categories
- [x] Intelligent severity scoring
- [x] RAG-enhanced AI explanations
- [x] GitHub Action integration
- [x] Web dashboard
- [x] Provenance tracking

### Phase 2 (Feb-Jun 2026)
- [ ] JavaScript/TypeScript adapter
- [ ] User study (8-10 participants)
- [ ] Precision/recall evaluation
- [ ] Production deployment
- [ ] Performance optimization

---

## ðŸ¤ Contributing

This is an academic project. Contributions welcome after June 2026 graduation.

---

## ðŸ“„ License

MIT License - See LICENSE file for details

---

## ðŸ™ Acknowledgments

- Dr. Samy AbdelNabi (Supervisor)
- Cerebras AI (Free API tier)
- CustomGPT (RAG architecture guidance)
- IEEE (Multi-language static analysis patterns)

---

**â­ Star this repo if you find it useful!**

Built with â¤ï¸ at King Salman International University

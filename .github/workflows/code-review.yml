name: ACR-QA Code Review

on:
  pull_request:
    types: [opened, synchronize, reopened]
    branches:
      - main
      - develop

jobs:
  code-review:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: acr_qa_db
          POSTGRES_USER: acr_user
          POSTGRES_PASSWORD: test_password_123
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: üì• Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better analysis

      - name: üêç Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: üì¶ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
          # Install analysis tools
          pip install ruff semgrep vulture radon bandit
          
          # Install Node.js for jscpd
          sudo apt-get update
          sudo apt-get install -y nodejs npm
          npm install -g jscpd

      - name: üóÑÔ∏è Initialize Database
        env:
          DB_NAME: acr_qa_db
          DB_USER: acr_user
          DB_PASSWORD: test_password_123
          DB_HOST: localhost
          DB_PORT: 5432
        run: |
          # Wait for PostgreSQL
          sleep 5
          
          # Initialize schema
          PGPASSWORD=test_password_123 psql -h localhost -U acr_user -d acr_qa_db -f db/schema.sql

      - name: üîç Run ACR-QA Analysis
        env:
          CEREBRAS_API_KEY: ${{ secrets.CEREBRAS_API_KEY }}
          DB_NAME: acr_qa_db
          DB_USER: acr_user
          DB_PASSWORD: test_password_123
          DB_HOST: localhost
          DB_PORT: 5432
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Run analysis pipeline
          python3 main.py \
            --repo-name ${{ github.repository }} \
            --pr-number ${{ github.event.pull_request.number }} \
            --limit 30

      - name: üí¨ Post PR Comments
        if: success()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Get latest run ID
          RUN_ID=$(python3 -c "from db.database import Database; db = Database(); runs = db.get_recent_runs(1); print(runs[0]['id'] if runs else '')")
          
          if [ ! -z "$RUN_ID" ]; then
            echo "Posting comments for run $RUN_ID"
            python3 scripts/post_comments.py \
              ${{ github.repository }} \
              ${{ github.event.pull_request.number }} \
              $RUN_ID \
              --max-comments 15
          else
            echo "No run ID found, skipping comment posting"
          fi

      - name: üìä Upload Analysis Report
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: acr-qa-report
          path: |
            outputs/report_*.md
            outputs/findings.json
            outputs/provenance/
          retention-days: 30

      - name: üìà Generate Summary
        if: always()
        run: |
          RUN_ID=$(python3 -c "from db.database import Database; db = Database(); runs = db.get_recent_runs(1); print(runs[0]['id'] if runs else '')")
          
          if [ ! -z "$RUN_ID" ]; then
            echo "## üîç ACR-QA Analysis Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Generate report
            python3 scripts/generate_report.py $RUN_ID
            
            # Add report summary to GitHub Actions summary
            if [ -f "outputs/report_run_${RUN_ID}.md" ]; then
              head -n 50 "outputs/report_run_${RUN_ID}.md" >> $GITHUB_STEP_SUMMARY
            fi
          fi

      - name: ‚ö†Ô∏è Check Quality Gate
        if: success()
        run: |
          RUN_ID=$(python3 -c "from db.database import Database; db = Database(); runs = db.get_recent_runs(1); print(runs[0]['id'] if runs else '')")
          
          if [ ! -z "$RUN_ID" ]; then
            # Count high-severity findings
            HIGH_COUNT=$(python3 -c "from db.database import Database; db = Database(); findings = db.get_findings_with_explanations($RUN_ID); print(sum(1 for f in findings if f['severity'] == 'error'))")
            
            echo "High-severity findings: $HIGH_COUNT"
            
            # Fail if too many critical issues (configurable threshold)
            THRESHOLD=5
            if [ "$HIGH_COUNT" -gt "$THRESHOLD" ]; then
              echo "‚ùå Quality gate failed: $HIGH_COUNT critical issues (threshold: $THRESHOLD)"
              exit 1
            else
              echo "‚úÖ Quality gate passed: $HIGH_COUNT critical issues (threshold: $THRESHOLD)"
            fi
          fi

# Optional: Scheduled analysis for main branch
on:
  schedule:
    # Run every day at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  scheduled-analysis:
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    
    steps:
      # Similar steps as above, but analyze entire codebase
      - name: üì• Checkout Code
        uses: actions/checkout@v4
      
      # ... (rest of setup steps)
      
      - name: üîç Full Codebase Analysis
        run: |
          python3 main.py \
            --repo-name ${{ github.repository }} \
            --target-dir .